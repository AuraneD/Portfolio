{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "146BB11JpfDA"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42hJEdo_pfDB"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbPhYVy_pfDB"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwhWZMI0pfDC"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR-TfDGrpfDC"
      },
      "outputs": [],
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-rs_ipfDE"
      },
      "source": [
        "# Install the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gti-w3eQoT3Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA1DIq5OpfDE",
        "outputId": "8be86fe7-349d-45ad-fff6-c72c1877029e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 66323, done.\u001b[K\n",
            "remote: Counting objects: 100% (140/140), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 66323 (delta 80), reused 110 (delta 52), pack-reused 66183\u001b[K\n",
            "Receiving objects: 100% (66323/66323), 575.86 MiB | 21.98 MiB/s, done.\n",
            "Resolving deltas: 100% (46448/46448), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJjMHbnDs3Tv",
        "outputId": "09b53506-2d97-4cc1-d146-7da96aaf1f79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: apt-get: command not found\n",
            "Processing /Users/Aurane/Desktop/TFODCourse/Tensorflow/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting apache-beam\n",
            "  Downloading apache_beam-2.33.0-cp38-cp38-macosx_10_9_x86_64.whl (4.2 MB)\n",
            "     |████████████████████████████████| 4.2 MB 5.7 MB/s            \n",
            "\u001b[?25hCollecting pillow\n",
            "  Downloading Pillow-8.4.0-cp38-cp38-macosx_10_10_x86_64.whl (3.0 MB)\n",
            "     |████████████████████████████████| 3.0 MB 10.6 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: lxml in /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages (from object-detection==0.1) (4.6.4)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.4.3-cp38-cp38-macosx_10_9_x86_64.whl (7.2 MB)\n",
            "     |████████████████████████████████| 7.2 MB 14.5 MB/s            \n",
            "\u001b[?25hCollecting Cython\n",
            "  Downloading Cython-0.29.24-cp38-cp38-macosx_10_9_x86_64.whl (1.9 MB)\n",
            "     |████████████████████████████████| 1.9 MB 22.7 MB/s            \n",
            "\u001b[?25hCollecting contextlib2\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "     |████████████████████████████████| 352 kB 47.3 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: six in /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages (from object-detection==0.1) (1.16.0)\n",
            "Collecting pycocotools\n",
            "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.7.2-cp38-cp38-macosx_10_9_x86_64.whl (33.0 MB)\n",
            "     |████████████████████████████████| 33.0 MB 256 kB/s            \n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-1.3.4-cp38-cp38-macosx_10_9_x86_64.whl (11.4 MB)\n",
            "     |████████████████████████████████| 11.4 MB 9.2 MB/s            \n",
            "\u001b[?25hCollecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.6.0-py2.py3-none-any.whl (1.8 MB)\n",
            "     |████████████████████████████████| 1.8 MB 8.9 MB/s            \n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.21.0-cp38-cp38-macosx_10_14_x86_64.whl (22.8 MB)\n",
            "     |████████████████████████████████| 22.8 MB 8.3 MB/s            \n",
            "\u001b[?25hCollecting keras==2.6.0\n",
            "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
            "     |████████████████████████████████| 1.3 MB 3.3 MB/s            \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "     |████████████████████████████████| 90 kB 5.4 MB/s             \n",
            "\u001b[?25hCollecting tensorflow-text>=2.5.0\n",
            "  Downloading tensorflow_text-2.6.0-cp38-cp38-macosx_10_9_x86_64.whl (3.6 MB)\n",
            "     |████████████████████████████████| 3.6 MB 9.1 MB/s            \n",
            "\u001b[?25hCollecting gin-config\n",
            "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
            "     |████████████████████████████████| 61 kB 6.8 MB/s             \n",
            "\u001b[?25hCollecting oauth2client\n",
            "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
            "     |████████████████████████████████| 98 kB 10.0 MB/s            \n",
            "\u001b[?25hCollecting google-api-python-client>=1.6.7\n",
            "  Downloading google_api_python_client-2.29.0-py2.py3-none-any.whl (7.7 MB)\n",
            "     |████████████████████████████████| 7.7 MB 576 kB/s            \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.4)\n",
            "Collecting psutil>=5.4.3\n",
            "  Downloading psutil-5.8.0-cp38-cp38-macosx_10_9_x86_64.whl (236 kB)\n",
            "     |████████████████████████████████| 236 kB 2.3 MB/s            \n",
            "\u001b[?25hCollecting tensorflow-hub>=0.6.0\n",
            "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
            "     |████████████████████████████████| 108 kB 5.3 MB/s            \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp38-cp38-macosx_10_9_x86_64.whl (192 kB)\n",
            "     |████████████████████████████████| 192 kB 3.2 MB/s            \n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "     |████████████████████████████████| 99 kB 5.1 MB/s             \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "     |████████████████████████████████| 43 kB 6.6 MB/s             \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp38-cp38-macosx_10_6_x86_64.whl (1.1 MB)\n",
            "     |████████████████████████████████| 1.1 MB 3.5 MB/s            \n",
            "\u001b[?25hCollecting kaggle>=1.3.9\n",
            "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
            "     |████████████████████████████████| 58 kB 5.5 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting tensorflow>=2.5.0\n",
            "  Downloading tensorflow-2.7.0-cp38-cp38-macosx_10_11_x86_64.whl (207.1 MB)\n",
            "     |████████████████████████████████| 207.1 MB 162 kB/s             \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.14.0-cp38-cp38-macosx_10_13_x86_64.whl (575 kB)\n",
            "     |████████████████████████████████| 575 kB 32.7 MB/s            \n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.4.58-cp38-cp38-macosx_10_15_x86_64.whl (45.5 MB)\n",
            "     |████████████████████████████████| 45.5 MB 15.9 MB/s            \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl (213 kB)\n",
            "     |████████████████████████████████| 213 kB 27.4 MB/s            \n",
            "\u001b[?25hCollecting tensorflow-datasets\n",
            "  Downloading tensorflow_datasets-4.4.0-py3-none-any.whl (4.0 MB)\n",
            "     |████████████████████████████████| 4.0 MB 30.8 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages (from pandas->object-detection==0.1) (2021.3)\n",
            "Collecting absl-py>=0.2.2\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "     |████████████████████████████████| 132 kB 21.2 MB/s            \n",
            "\u001b[?25hCollecting pydot<2,>=1.2.0\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.6.4-cp38-cp38-macosx_10_9_x86_64.macosx_11_0_arm64.macosx_10_9_universal2.whl (444 kB)\n",
            "     |████████████████████████████████| 444 kB 25.5 MB/s            \n",
            "\u001b[?25hCollecting protobuf<4,>=3.12.2\n",
            "  Downloading protobuf-3.19.1-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
            "     |████████████████████████████████| 1.0 MB 32.1 MB/s            \n",
            "\u001b[?25hCollecting httplib2<0.20.0,>=0.8\n",
            "  Downloading httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
            "     |████████████████████████████████| 95 kB 15.1 MB/s            \n",
            "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.1-cp38-cp38-macosx_10_9_x86_64.whl (395 kB)\n",
            "     |████████████████████████████████| 395 kB 26.0 MB/s            \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "     |████████████████████████████████| 151 kB 30.0 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting fastavro<2,>=0.21.4\n",
            "  Downloading fastavro-1.4.7-cp38-cp38-macosx_10_14_x86_64.whl (485 kB)\n",
            "     |████████████████████████████████| 485 kB 29.2 MB/s            \n",
            "\u001b[?25hCollecting future<1.0.0,>=0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "     |████████████████████████████████| 829 kB 15.8 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting typing-extensions<4,>=3.7.0\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Collecting grpcio<2,>=1.29.0\n",
            "  Downloading grpcio-1.41.1-cp38-cp38-macosx_10_10_x86_64.whl (3.9 MB)\n",
            "     |████████████████████████████████| 3.9 MB 33.0 MB/s            \n",
            "\u001b[?25hCollecting numpy>=1.15.4\n",
            "  Downloading numpy-1.20.3-cp38-cp38-macosx_10_9_x86_64.whl (16.0 MB)\n",
            "     |████████████████████████████████| 16.0 MB 4.0 MB/s            \n",
            "\u001b[?25hCollecting avro-python3\n",
            "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting requests<3.0.0,>=2.24.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "     |████████████████████████████████| 62 kB 3.1 MB/s             \n",
            "\u001b[?25hCollecting crcmod<2.0,>=1.7\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "     |████████████████████████████████| 89 kB 17.9 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting pyarrow<5.0.0,>=0.15.1\n",
            "  Downloading pyarrow-4.0.1-cp38-cp38-macosx_10_13_x86_64.whl (15.7 MB)\n",
            "     |████████████████████████████████| 15.7 MB 30.0 MB/s            \n",
            "\u001b[?25hCollecting cycler>=0.10.0\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages (from lvis->object-detection==0.1) (4.5.4.58)\n",
            "Collecting kiwisolver>=1.1.0\n",
            "  Downloading kiwisolver-1.3.2-cp38-cp38-macosx_10_9_x86_64.whl (61 kB)\n",
            "     |████████████████████████████████| 61 kB 766 kB/s             \n",
            "\u001b[?25hCollecting pyparsing>=2.4.0\n",
            "  Downloading pyparsing-3.0.4-py3-none-any.whl (96 kB)\n",
            "     |████████████████████████████████| 96 kB 18.0 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.0 in /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages (from pycocotools->object-detection==0.1) (47.1.0)\n",
            "Collecting tensorflow-io-gcs-filesystem==0.21.0\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.21.0-cp38-cp38-macosx_10_14_x86_64.whl (1.6 MB)\n",
            "     |████████████████████████████████| 1.6 MB 55.9 MB/s            \n",
            "\u001b[?25hCollecting tensorflow>=2.5.0\n",
            "  Downloading tensorflow-2.6.2-cp38-cp38-macosx_10_11_x86_64.whl (199.0 MB)\n",
            "     |████████████████████████████████| 199.0 MB 98.5 MB/s            \n",
            "\u001b[?25hCollecting google-auth-httplib2>=0.1.0\n",
            "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting uritemplate<5,>=3.0.0\n",
            "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Collecting google-api-core<3.0.0dev,>=1.21.0\n",
            "  Downloading google_api_core-2.2.2-py2.py3-none-any.whl (95 kB)\n",
            "     |████████████████████████████████| 95 kB 22.8 MB/s            \n",
            "\u001b[?25hCollecting google-auth<3.0.0dev,>=1.16.0\n",
            "  Downloading google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
            "     |████████████████████████████████| 155 kB 14.7 MB/s            \n",
            "\u001b[?25hCollecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting pyparsing>=2.4.0\n",
            "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "Collecting certifi\n",
            "  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
            "     |████████████████████████████████| 149 kB 25.6 MB/s            \n",
            "\u001b[?25hCollecting tqdm\n",
            "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
            "     |████████████████████████████████| 76 kB 8.6 MB/s             \n",
            "\u001b[?25hCollecting python-slugify\n",
            "  Downloading python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "     |████████████████████████████████| 138 kB 24.9 MB/s            \n",
            "\u001b[?25hCollecting pyasn1>=0.1.7\n",
            "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Collecting rsa>=3.1.4\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting pyasn1-modules>=0.0.5\n",
            "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
            "     |████████████████████████████████| 61 kB 19.5 MB/s            \n",
            "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
            "  Downloading charset_normalizer-2.0.7-py3-none-any.whl (38 kB)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting keras-preprocessing~=1.1.2\n",
            "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Collecting tensorboard<2.7,>=2.6.0\n",
            "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
            "     |████████████████████████████████| 5.6 MB 12.0 MB/s            \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.7,>=2.6.0\n",
            "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
            "     |████████████████████████████████| 462 kB 56.4 MB/s            \n",
            "\u001b[?25hCollecting termcolor~=1.1.0\n",
            "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
            "Collecting typing-extensions<4,>=3.7.0\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting wheel~=0.35\n",
            "  Downloading wheel-0.37.0-py2.py3-none-any.whl (35 kB)\n",
            "Collecting astunparse~=1.6.3\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting google-pasta~=0.2\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Collecting numpy>=1.15.4\n",
            "  Downloading numpy-1.19.5-cp38-cp38-macosx_10_9_x86_64.whl (15.6 MB)\n",
            "     |████████████████████████████████| 15.6 MB 16.3 MB/s            \n",
            "\u001b[?25hCollecting gast==0.4.0\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting opt-einsum~=3.3.0\n",
            "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "Collecting clang~=5.0\n",
            "  Downloading clang-5.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting h5py~=3.1.0\n",
            "  Downloading h5py-3.1.0-cp38-cp38-macosx_10_9_x86_64.whl (2.9 MB)\n",
            "     |████████████████████████████████| 2.9 MB 41.3 MB/s            \n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Using cached wrapt-1.12.1-cp38-cp38-macosx_10_9_x86_64.whl\n",
            "Collecting dm-tree~=0.1.1\n",
            "  Downloading dm_tree-0.1.6-cp38-cp38-macosx_10_14_x86_64.whl (95 kB)\n",
            "     |████████████████████████████████| 95 kB 9.3 MB/s             \n",
            "\u001b[?25hCollecting regex\n",
            "  Downloading regex-2021.11.2-cp38-cp38-macosx_10_9_x86_64.whl (288 kB)\n",
            "     |████████████████████████████████| 288 kB 18.5 MB/s            \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting tabulate>=0.8.9\n",
            "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
            "Collecting scikit-learn>=0.21.3\n",
            "  Downloading scikit_learn-1.0.1-cp38-cp38-macosx_10_13_x86_64.whl (7.9 MB)\n",
            "     |████████████████████████████████| 7.9 MB 11.1 MB/s            \n",
            "\u001b[?25hCollecting typeguard>=2.7\n",
            "  Downloading typeguard-2.13.0-py3-none-any.whl (17 kB)\n",
            "Collecting importlib-resources\n",
            "  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
            "Collecting tensorflow-metadata\n",
            "  Downloading tensorflow_metadata-1.4.0-py3-none-any.whl (48 kB)\n",
            "     |████████████████████████████████| 48 kB 8.2 MB/s             \n",
            "\u001b[?25hCollecting attrs>=18.1.0\n",
            "  Downloading attrs-21.2.0-py2.py3-none-any.whl (53 kB)\n",
            "     |████████████████████████████████| 53 kB 7.1 MB/s             \n",
            "\u001b[?25hCollecting promise\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting googleapis-common-protos<2.0dev,>=1.52.0\n",
            "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
            "     |████████████████████████████████| 198 kB 41.2 MB/s            \n",
            "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
            "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
            "Collecting joblib>=0.11\n",
            "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
            "     |████████████████████████████████| 306 kB 24.0 MB/s            \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting google-auth<3.0.0dev,>=1.16.0\n",
            "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
            "     |████████████████████████████████| 152 kB 19.0 MB/s            \n",
            "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
            "     |████████████████████████████████| 3.5 MB 27.6 MB/s            \n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
            "     |████████████████████████████████| 97 kB 14.7 MB/s            \n",
            "\u001b[?25hCollecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
            "     |████████████████████████████████| 288 kB 26.8 MB/s            \n",
            "\u001b[?25hCollecting zipp>=3.1.0\n",
            "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting text-unidecode>=1.3\n",
            "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "     |████████████████████████████████| 78 kB 11.7 MB/s            \n",
            "\u001b[?25hCollecting absl-py>=0.2.2\n",
            "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
            "     |████████████████████████████████| 129 kB 24.0 MB/s            \n",
            "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
            "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
            "     |████████████████████████████████| 146 kB 25.7 MB/s            \n",
            "\u001b[?25hUsing legacy 'setup.py install' for object-detection, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for avro-python3, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for pycocotools, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for crcmod, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for dill, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for future, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for kaggle, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for py-cpuinfo, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for seqeval, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for clang, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for docopt, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for promise, since package 'wheel' is not installed.\n",
            "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, certifi, six, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, wheel, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, pyparsing, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, zipp, wrapt, typing-extensions, threadpoolctl, text-unidecode, termcolor, tensorflow-estimator, tensorboard, scipy, pillow, opt-einsum, kiwisolver, keras-preprocessing, keras, joblib, httplib2, h5py, googleapis-common-protos, google-pasta, gast, flatbuffers, cycler, clang, astunparse, uritemplate, typeguard, tqdm, tensorflow-metadata, tensorflow-hub, tensorflow, tabulate, scikit-learn, regex, python-slugify, promise, portalocker, matplotlib, importlib-resources, google-auth-httplib2, google-api-core, future, docopt, dm-tree, dill, Cython, colorama, attrs, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-io-gcs-filesystem, tensorflow-datasets, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, pydot, pycocotools, pyarrow, py-cpuinfo, psutil, pandas, orjson, opencv-python-headless, oauth2client, kaggle, hdfs, google-api-python-client, gin-config, fastavro, crcmod, avro-python3, tf-models-official, tensorflow-io, lvis, contextlib2, apache-beam, object-detection\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.4\n",
            "    Uninstalling numpy-1.21.4:\n",
            "      Successfully uninstalled numpy-1.21.4\n",
            "    Running setup.py install for clang ... \u001b[?25ldone\n",
            "\u001b[?25h    Running setup.py install for promise ... \u001b[?25ldone\n",
            "\u001b[?25h    Running setup.py install for future ... \u001b[?25ldone\n",
            "\u001b[?25h    Running setup.py install for docopt ... \u001b[?25ldone\n",
            "\u001b[?25h    Running setup.py install for dill ... \u001b[?25ldone\n",
            "\u001b[?25h    Running setup.py install for seqeval ... \u001b[?25ldone\n",
            "\u001b[?25h    Running setup.py install for pycocotools ... \u001b[?25ldone\n",
            "\u001b[?25h    Running setup.py install for py-cpuinfo ... \u001b[?25ldone\n",
            "\u001b[?25h    Running setup.py install for kaggle ... \u001b[?25ldone\n",
            "\u001b[?25h    Running setup.py install for crcmod ... \u001b[?25ldone\n",
            "\u001b[?25h    Running setup.py install for avro-python3 ... \u001b[?25ldone\n",
            "\u001b[?25h    Running setup.py install for object-detection ... \u001b[?25ldone\n",
            "\u001b[?25hSuccessfully installed Cython-0.29.24 absl-py-0.12.0 apache-beam-2.33.0 astunparse-1.6.3 attrs-21.2.0 avro-python3-1.9.2.1 cachetools-4.2.4 certifi-2021.10.8 charset-normalizer-2.0.7 clang-5.0 colorama-0.4.4 contextlib2-21.6.0 crcmod-1.7 cycler-0.11.0 dill-0.3.1.1 dm-tree-0.1.6 docopt-0.6.2 fastavro-1.4.7 flatbuffers-1.12 future-0.18.2 gast-0.4.0 gin-config-0.5.0 google-api-core-2.2.2 google-api-python-client-2.29.0 google-auth-1.35.0 google-auth-httplib2-0.1.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 googleapis-common-protos-1.53.0 grpcio-1.41.1 h5py-3.1.0 hdfs-2.6.0 httplib2-0.19.1 idna-3.3 importlib-resources-5.4.0 joblib-1.1.0 kaggle-1.5.12 keras-2.6.0 keras-preprocessing-1.1.2 kiwisolver-1.3.2 lvis-0.5.3 markdown-3.3.4 matplotlib-3.4.3 numpy-1.19.5 oauth2client-4.1.3 oauthlib-3.1.1 object-detection-0.1 opencv-python-headless-4.5.4.58 opt-einsum-3.3.0 orjson-3.6.4 pandas-1.3.4 pillow-8.4.0 portalocker-2.3.2 promise-2.3 protobuf-3.19.1 psutil-5.8.0 py-cpuinfo-8.0.0 pyarrow-4.0.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycocotools-2.0.2 pydot-1.4.2 pymongo-3.12.1 pyparsing-2.4.7 python-slugify-5.0.2 pyyaml-6.0 regex-2021.11.2 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.7.2 sacrebleu-2.0.0 scikit-learn-1.0.1 scipy-1.7.2 sentencepiece-0.1.96 seqeval-1.2.2 six-1.15.0 tabulate-0.8.9 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.2 tensorflow-addons-0.14.0 tensorflow-datasets-4.4.0 tensorflow-estimator-2.6.0 tensorflow-hub-0.12.0 tensorflow-io-0.21.0 tensorflow-io-gcs-filesystem-0.21.0 tensorflow-metadata-1.4.0 tensorflow-model-optimization-0.7.0 tensorflow-text-2.6.0 termcolor-1.1.0 text-unidecode-1.3 tf-models-official-2.6.0 tf-slim-1.1.0 threadpoolctl-3.0.0 tqdm-4.62.3 typeguard-2.13.0 typing-extensions-3.7.4.3 uritemplate-4.1.1 urllib3-1.26.7 werkzeug-2.0.2 wheel-0.37.0 wrapt-1.12.1 zipp-3.6.0\n"
          ]
        }
      ],
      "source": [
        "# Install Tensorflow Object Detection \n",
        "if os.name=='posix':  \n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
        "    \n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "MoLc5syZoT3a",
        "outputId": "e9a1f0b1-d1f6-442d-927e-773a3b1587e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running tests under Python 3.8.5: /Users/Aurane/Desktop/TFODCourse/tfod/bin/python\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2021-11-06 17:57:50.465313: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages/object_detection/builders/model_builder.py:1100: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
            "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
            "W1106 17:57:50.783241 4453682688 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.6s\n",
            "I1106 17:57:51.064450 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.6s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.91s\n",
            "I1106 17:57:51.977401 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.91s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.36s\n",
            "I1106 17:57:52.337547 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.36s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.24s\n",
            "I1106 17:57:52.582730 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.24s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.72s\n",
            "I1106 17:57:54.302895 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.72s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1106 17:57:54.303975 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.16s\n",
            "I1106 17:57:54.465189 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.16s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I1106 17:57:54.478631 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I1106 17:57:54.498747 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n",
            "I1106 17:57:54.607642 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "I1106 17:57:54.697483 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n",
            "I1106 17:57:54.810565 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n",
            "I1106 17:57:54.924233 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "I1106 17:57:55.023557 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I1106 17:57:55.055094 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1106 17:57:55.226579 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1106 17:57:55.226701 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
            "I1106 17:57:55.226752 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 3\n",
            "I1106 17:57:55.228690 4453682688 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I1106 17:57:55.247731 4453682688 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I1106 17:57:55.247888 4453682688 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I1106 17:57:55.304560 4453682688 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I1106 17:57:55.304709 4453682688 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I1106 17:57:55.457188 4453682688 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I1106 17:57:55.457338 4453682688 efficientnet_model.py:147] round_filter input=40 output=40\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I1106 17:57:55.598127 4453682688 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I1106 17:57:55.598321 4453682688 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I1106 17:57:55.839617 4453682688 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I1106 17:57:55.839802 4453682688 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I1106 17:57:56.107034 4453682688 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I1106 17:57:56.107161 4453682688 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I1106 17:57:56.462336 4453682688 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I1106 17:57:56.462469 4453682688 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I1106 17:57:56.555382 4453682688 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I1106 17:57:56.603394 4453682688 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1106 17:57:56.670554 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1106 17:57:56.670704 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
            "I1106 17:57:56.670766 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 4\n",
            "I1106 17:57:56.672357 4453682688 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I1106 17:57:56.689294 4453682688 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I1106 17:57:56.689456 4453682688 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I1106 17:57:56.830440 4453682688 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I1106 17:57:56.830576 4453682688 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I1106 17:57:57.085219 4453682688 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I1106 17:57:57.085399 4453682688 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I1106 17:57:57.376143 4453682688 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I1106 17:57:57.376293 4453682688 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I1106 17:57:57.905386 4453682688 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I1106 17:57:57.905546 4453682688 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I1106 17:57:58.276489 4453682688 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I1106 17:57:58.276623 4453682688 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I1106 17:57:58.759773 4453682688 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I1106 17:57:58.759906 4453682688 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I1106 17:57:58.941351 4453682688 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I1106 17:57:58.976768 4453682688 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1106 17:57:59.058339 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1106 17:57:59.058469 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
            "I1106 17:57:59.058527 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 5\n",
            "I1106 17:57:59.060123 4453682688 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I1106 17:57:59.075738 4453682688 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I1106 17:57:59.075855 4453682688 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I1106 17:57:59.211452 4453682688 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I1106 17:57:59.211585 4453682688 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I1106 17:57:59.446771 4453682688 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I1106 17:57:59.446948 4453682688 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I1106 17:57:59.681595 4453682688 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I1106 17:57:59.681776 4453682688 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I1106 17:58:00.075142 4453682688 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I1106 17:58:00.075273 4453682688 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I1106 17:58:00.435046 4453682688 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I1106 17:58:00.435228 4453682688 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I1106 17:58:00.874324 4453682688 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I1106 17:58:00.874457 4453682688 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I1106 17:58:01.050612 4453682688 efficientnet_model.py:147] round_filter input=1280 output=1408\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I1106 17:58:01.091557 4453682688 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1106 17:58:01.167448 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1106 17:58:01.167572 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
            "I1106 17:58:01.167625 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 6\n",
            "I1106 17:58:01.169215 4453682688 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I1106 17:58:01.185009 4453682688 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I1106 17:58:01.185235 4453682688 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I1106 17:58:01.311288 4453682688 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I1106 17:58:01.311416 4453682688 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I1106 17:58:01.535551 4453682688 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I1106 17:58:01.535701 4453682688 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I1106 17:58:01.763113 4453682688 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I1106 17:58:01.763242 4453682688 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I1106 17:58:02.321918 4453682688 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I1106 17:58:02.322053 4453682688 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I1106 17:58:02.681732 4453682688 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I1106 17:58:02.681852 4453682688 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I1106 17:58:03.171429 4453682688 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I1106 17:58:03.171558 4453682688 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I1106 17:58:03.356144 4453682688 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I1106 17:58:03.397301 4453682688 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1106 17:58:03.473392 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1106 17:58:03.473521 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
            "I1106 17:58:03.473578 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 7\n",
            "I1106 17:58:03.475188 4453682688 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I1106 17:58:03.493189 4453682688 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I1106 17:58:03.493349 4453682688 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I1106 17:58:03.619575 4453682688 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I1106 17:58:03.619697 4453682688 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I1106 17:58:03.960730 4453682688 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I1106 17:58:03.960858 4453682688 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I1106 17:58:04.250265 4453682688 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I1106 17:58:04.250390 4453682688 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I1106 17:58:04.683850 4453682688 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I1106 17:58:04.683974 4453682688 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I1106 17:58:05.116220 4453682688 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I1106 17:58:05.116346 4453682688 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I1106 17:58:05.749960 4453682688 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I1106 17:58:05.750096 4453682688 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I1106 17:58:05.921330 4453682688 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I1106 17:58:05.969319 4453682688 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I1106 17:58:06.049973 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1106 17:58:06.050097 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
            "I1106 17:58:06.050149 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 7\n",
            "I1106 17:58:06.051959 4453682688 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I1106 17:58:06.066119 4453682688 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I1106 17:58:06.066236 4453682688 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I1106 17:58:06.258146 4453682688 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I1106 17:58:06.258268 4453682688 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I1106 17:58:06.806678 4453682688 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I1106 17:58:06.806807 4453682688 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I1106 17:58:07.180773 4453682688 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I1106 17:58:07.180897 4453682688 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I1106 17:58:07.682183 4453682688 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I1106 17:58:07.682365 4453682688 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I1106 17:58:08.221972 4453682688 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I1106 17:58:08.222100 4453682688 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I1106 17:58:08.979833 4453682688 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I1106 17:58:08.979961 4453682688 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I1106 17:58:09.273511 4453682688 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I1106 17:58:09.324966 4453682688 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1106 17:58:09.427276 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1106 17:58:09.427402 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I1106 17:58:09.427458 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 8\n",
            "I1106 17:58:09.428947 4453682688 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I1106 17:58:09.448874 4453682688 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I1106 17:58:09.449002 4453682688 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I1106 17:58:09.628645 4453682688 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I1106 17:58:09.628771 4453682688 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I1106 17:58:10.104574 4453682688 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I1106 17:58:10.104698 4453682688 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I1106 17:58:10.557826 4453682688 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I1106 17:58:10.557950 4453682688 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I1106 17:58:11.353374 4453682688 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I1106 17:58:11.353498 4453682688 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I1106 17:58:11.967689 4453682688 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I1106 17:58:11.967813 4453682688 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I1106 17:58:12.946753 4453682688 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I1106 17:58:12.946930 4453682688 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I1106 17:58:13.308239 4453682688 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I1106 17:58:13.359642 4453682688 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1106 17:58:13.475069 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:142] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1106 17:58:13.475198 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I1106 17:58:13.475255 4453682688 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num iterations: 8\n",
            "I1106 17:58:13.476712 4453682688 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I1106 17:58:13.493660 4453682688 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I1106 17:58:13.493818 4453682688 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I1106 17:58:13.750290 4453682688 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I1106 17:58:13.750473 4453682688 efficientnet_model.py:147] round_filter input=24 output=48\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I1106 17:58:14.311301 4453682688 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I1106 17:58:14.311461 4453682688 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I1106 17:58:14.945642 4453682688 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I1106 17:58:14.945829 4453682688 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I1106 17:58:15.913146 4453682688 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I1106 17:58:15.913279 4453682688 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I1106 17:58:17.022044 4453682688 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I1106 17:58:17.022173 4453682688 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I1106 17:58:18.241384 4453682688 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I1106 17:58:18.241563 4453682688 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I1106 17:58:18.774039 4453682688 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I1106 17:58:18.858335 4453682688 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 23.96s\n",
            "I1106 17:58:19.011151 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 23.96s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I1106 17:58:19.020509 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I1106 17:58:19.022149 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I1106 17:58:19.022562 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I1106 17:58:19.024005 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I1106 17:58:19.025223 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I1106 17:58:19.025530 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I1106 17:58:19.026403 4453682688 test_util.py:2188] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 28.566s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "oD-BVob6oT3b",
        "outputId": "dc4d0ed5-6170-4bed-f089-01480d45445c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages\\tensorflow-2.5.0rc0-py3.7-win-amd64.egg (2.5.0rc0)\n",
            "Requirement already satisfied: absl-py~=0.10 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow) (0.12.0)\n",
            "Collecting astunparse~=1.6.3\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting gast==0.4.0\n",
            "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting google-pasta~=0.2\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Using cached grpcio-1.34.1-cp37-cp37m-win_amd64.whl (2.9 MB)\n",
            "Collecting h5py~=3.1.0\n",
            "  Using cached h5py-3.1.0-cp37-cp37m-win_amd64.whl (2.7 MB)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Using cached keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "Collecting keras-preprocessing~=1.1.2\n",
            "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Requirement already satisfied: numpy~=1.19.2 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow) (1.19.5)\n",
            "Collecting opt-einsum~=3.3.0\n",
            "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow) (3.15.7)\n",
            "Requirement already satisfied: six~=1.15.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow) (1.15.0)\n",
            "Collecting tensorboard~=2.4\n",
            "  Using cached tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
            "Collecting termcolor~=1.1.0\n",
            "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
            "Collecting tf-estimator-nightly==2.5.0.dev2021032501\n",
            "  Using cached tf_estimator_nightly-2.5.0.dev2021032501-py2.py3-none-any.whl (462 kB)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages\\typing_extensions-3.7.4.3-py3.7.egg (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: wheel~=0.35 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorflow) (0.36.2)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Using cached wrapt-1.12.1-cp37-cp37m-win_amd64.whl\n",
            "Collecting cached-property\n",
            "  Using cached cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.28.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Using cached google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages\\requests-2.25.1-py3.7.egg (from tensorboard~=2.4->tensorflow) (2.25.1)\n",
            "Collecting markdown>=2.6.8\n",
            "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (54.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n",
            "Installing collected packages: markdown, grpcio, google-auth-oauthlib, cached-property, wrapt, tf-estimator-nightly, termcolor, tensorboard, opt-einsum, keras-preprocessing, keras-nightly, h5py, google-pasta, gast, flatbuffers, astunparse\n",
            "Successfully installed astunparse-1.6.3 cached-property-1.5.2 flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 opt-einsum-3.3.0 tensorboard-2.4.1 termcolor-1.1.0 tf-estimator-nightly-2.5.0.dev2021032501 wrapt-1.12.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "apache-beam 2.28.0 requires crcmod<2.0,>=1.7, which is not installed.\n",
            "apache-beam 2.28.0 requires dill<0.3.2,>=0.3.1.1, which is not installed.\n",
            "apache-beam 2.28.0 requires fastavro<2,>=0.21.4, which is not installed.\n",
            "apache-beam 2.28.0 requires future<1.0.0,>=0.18.2, which is not installed.\n",
            "apache-beam 2.28.0 requires hdfs<3.0.0,>=2.1.0, which is not installed.\n",
            "apache-beam 2.28.0 requires httplib2<0.18.0,>=0.8, which is not installed.\n",
            "apache-beam 2.28.0 requires mock<3.0.0,>=1.0.1, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires attrs>=18.1.0, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires dill, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires future, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires importlib-resources, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires promise, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires tensorflow-metadata, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires tqdm, which is not installed.\n",
            "apache-beam 2.28.0 requires avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you have avro-python3 1.10.2 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "oozCdgsooT3c",
        "outputId": "7a61fce5-b1bf-40db-f5a6-9e00374e86c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: protobuf 3.15.7\n",
            "Uninstalling protobuf-3.15.7:\n",
            "  Successfully uninstalled protobuf-3.15.7\n",
            "Found existing installation: matplotlib 3.4.1\n",
            "Uninstalling matplotlib-3.4.1:\n",
            "  Successfully uninstalled matplotlib-3.4.1\n",
            "Collecting protobuf"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "apache-beam 2.28.0 requires crcmod<2.0,>=1.7, which is not installed.\n",
            "apache-beam 2.28.0 requires dill<0.3.2,>=0.3.1.1, which is not installed.\n",
            "apache-beam 2.28.0 requires fastavro<2,>=0.21.4, which is not installed.\n",
            "apache-beam 2.28.0 requires future<1.0.0,>=0.18.2, which is not installed.\n",
            "apache-beam 2.28.0 requires grpcio<2,>=1.29.0, which is not installed.\n",
            "apache-beam 2.28.0 requires hdfs<3.0.0,>=2.1.0, which is not installed.\n",
            "apache-beam 2.28.0 requires httplib2<0.18.0,>=0.8, which is not installed.\n",
            "apache-beam 2.28.0 requires mock<3.0.0,>=1.0.1, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires astunparse~=1.6.3, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires flatbuffers~=1.12.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires gast==0.4.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires google-pasta~=0.2, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires grpcio~=1.34.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires h5py~=3.1.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires keras-nightly~=2.5.0.dev, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires keras-preprocessing~=1.1.2, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires opt-einsum~=3.3.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires tensorboard~=2.4, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires termcolor~=1.1.0, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires tf-estimator-nightly==2.5.0.dev2021032501, which is not installed.\n",
            "tensorflow 2.5.0rc0 requires wrapt~=1.12.1, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires attrs>=18.1.0, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires dill, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires future, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires importlib-resources, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires promise, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires tensorflow-metadata, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires termcolor, which is not installed.\n",
            "tensorflow-datasets 4.2.0 requires tqdm, which is not installed.\n",
            "google-cloud-bigquery 2.13.1 requires google-api-core[grpc]<2.0.0dev,>=1.23.0, which is not installed.\n",
            "google-cloud-bigquery 2.13.1 requires google-cloud-core<2.0dev,>=1.4.1, which is not installed.\n",
            "google-cloud-bigquery 2.13.1 requires google-resumable-media<2.0dev,>=0.6.0, which is not installed.\n",
            "google-cloud-bigquery 2.13.1 requires packaging>=14.3, which is not installed.\n",
            "google-cloud-bigquery 2.13.1 requires proto-plus>=1.10.0, which is not installed.\n",
            "apache-beam 2.28.0 requires avro-python3!=1.9.2,<1.10.0,>=1.8.1, but you have avro-python3 1.10.2 which is incompatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Downloading protobuf-3.15.7-cp37-cp37m-win_amd64.whl (904 kB)\n",
            "Collecting matplotlib==3.2\n",
            "  Using cached matplotlib-3.2.0-cp37-cp37m-win_amd64.whl (9.2 MB)\n",
            "Requirement already satisfied: cycler>=0.10 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages\\cycler-0.10.0-py3.7.egg (from matplotlib==3.2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages\\kiwisolver-1.3.1-py3.7-win-amd64.egg (from matplotlib==3.2) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from matplotlib==3.2) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages\\pyparsing-3.0.0b2-py3.7.egg (from matplotlib==3.2) (3.0.0b2)\n",
            "Requirement already satisfied: numpy>=1.11 in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from matplotlib==3.2) (1.19.5)\n",
            "Requirement already satisfied: six in d:\\youtube\\od\\tfodcourse\\tfod\\lib\\site-packages (from cycler>=0.10->matplotlib==3.2) (1.15.0)\n",
            "Installing collected packages: protobuf, matplotlib\n",
            "Successfully installed matplotlib-3.2.0 protobuf-3.15.7\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall protobuf matplotlib -y\n",
        "!pip install protobuf matplotlib==3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qjRMwocoT3c"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "yV2iDlxgoT3d",
        "outputId": "6b298c3a-1b8b-46ec-e990-4fd1aac780d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package                       Version             Location\n",
            "----------------------------- ------------------- --------------------------------------------------------\n",
            "absl-py                       0.12.0\n",
            "apache-beam                   2.28.0\n",
            "astunparse                    1.6.3\n",
            "avro-python3                  1.10.2\n",
            "backcall                      0.2.0\n",
            "cached-property               1.5.2\n",
            "cachetools                    4.2.1\n",
            "certifi                       2020.12.5\n",
            "chardet                       4.0.0\n",
            "colorama                      0.4.4\n",
            "contextlib2                   0.6.0.post1\n",
            "cycler                        0.10.0\n",
            "cython                        3.0a6\n",
            "dataclasses                   0.8\n",
            "decorator                     5.0.3\n",
            "flatbuffers                   1.12\n",
            "gast                          0.4.0\n",
            "gin-config                    0.4.0\n",
            "google-api-python-client      2.1.0\n",
            "google-auth                   1.28.0\n",
            "google-auth-oauthlib          0.4.4\n",
            "google-cloud-bigquery         2.13.1\n",
            "google-pasta                  0.2.0\n",
            "grpcio                        1.34.1\n",
            "h5py                          3.1.0\n",
            "idna                          2.10\n",
            "importlib-metadata            3.10.0\n",
            "ipykernel                     5.5.3\n",
            "ipython                       7.22.0\n",
            "ipython-genutils              0.2.0\n",
            "jedi                          0.18.0\n",
            "jupyter-client                6.1.12\n",
            "jupyter-core                  4.7.1\n",
            "kaggle                        1.5.12\n",
            "keras-nightly                 2.5.0.dev2021032900\n",
            "Keras-Preprocessing           1.1.2\n",
            "kiwisolver                    1.3.1\n",
            "lvis                          0.5.3\n",
            "lxml                          4.6.3\n",
            "Markdown                      3.3.4\n",
            "matplotlib                    3.2.0\n",
            "numpy                         1.19.5\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.1.0\n",
            "object-detection              0.1\n",
            "opencv-python                 4.5.1.48\n",
            "opencv-python-headless        4.5.1.48\n",
            "opt-einsum                    3.3.0\n",
            "pandas                        1.2.3\n",
            "parso                         0.8.2\n",
            "pickleshare                   0.7.5\n",
            "pillow                        8.2.0\n",
            "pip                           21.0.1\n",
            "prompt-toolkit                3.0.18\n",
            "protobuf                      3.15.7\n",
            "psutil                        5.8.0\n",
            "py-cpuinfo                    7.0.0\n",
            "pyarrow                       2.0.0\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.2\n",
            "pydot                         1.4.2\n",
            "Pygments                      2.8.1\n",
            "pymongo                       3.11.3\n",
            "pyparsing                     3.0.0b2\n",
            "PyQt5                         5.15.4\n",
            "PyQt5-Qt5                     5.15.2\n",
            "PyQt5-sip                     12.8.1\n",
            "python-dateutil               2.8.1\n",
            "pytz                          2021.1\n",
            "pywin32                       300\n",
            "pyyaml                        5.4.1\n",
            "pyzmq                         22.0.3\n",
            "requests                      2.25.1\n",
            "requests-oauthlib             1.3.0\n",
            "rsa                           4.7.2\n",
            "scipy                         1.6.2\n",
            "sentencepiece                 0.1.95\n",
            "seqeval                       1.2.2\n",
            "setuptools                    54.2.0\n",
            "six                           1.15.0\n",
            "slim                          0.1                 d:\\youtube\\od\\tfodcourse\\tensorflow\\models\\research\\slim\n",
            "tensorboard                   2.4.1\n",
            "tensorboard-plugin-wit        1.8.0\n",
            "tensorflow                    2.5.0rc0\n",
            "tensorflow-addons             0.12.1\n",
            "tensorflow-datasets           4.2.0\n",
            "tensorflow-hub                0.11.0\n",
            "tensorflow-model-optimization 0.5.0\n",
            "termcolor                     1.1.0\n",
            "tf-estimator-nightly          2.5.0.dev2021032501\n",
            "tf-models-official            2.4.0\n",
            "tf-slim                       1.1.0\n",
            "tornado                       6.1\n",
            "traitlets                     5.0.5\n",
            "typing-extensions             3.7.4.3\n",
            "urllib3                       1.26.4\n",
            "wcwidth                       0.2.5\n",
            "Werkzeug                      1.0.1\n",
            "wget                          3.2\n",
            "wheel                         0.36.2\n",
            "wrapt                         1.12.1\n",
            "zipp                          3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csofht2npfDE",
        "outputId": "ff5471b2-bed2-43f2-959c-327a706527b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-11-06 19:13:44--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Résolution de download.tensorflow.org (download.tensorflow.org)… 2a00:1450:4007:80c::2010, 172.217.18.208\n",
            "Connexion à download.tensorflow.org (download.tensorflow.org)|2a00:1450:4007:80c::2010|:80… connecté.\n",
            "requête HTTP transmise, en attente de la réponse… 200 OK\n",
            "Taille : 20515344 (20M) [application/x-tar]\n",
            "Sauvegarde en : « ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz »\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19,56M  30,1MB/s    ds 0,6s    \n",
            "\n",
            "2021-11-06 19:13:46 (30,1 MB/s) — « ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz » sauvegardé [20515344/20515344]\n",
            "\n",
            "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KJTnkfpfDC"
      },
      "source": [
        "# 2. Create Label Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1BVDWo7pfDC"
      },
      "outputs": [],
      "source": [
        "labels = [{'name':'endometriosis', 'id':1}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C88zyVELpfDC"
      },
      "source": [
        "# 3. Create TF records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWpb_BVUpfDD",
        "outputId": "56ce2a3f-3933-4ee6-8a9d-d5ec65f7d73c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Tensorflow/scripts'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPFToGZqpfDD",
        "outputId": "0ebb456f-aadc-4a1f-96e6-fbfec1923e1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4QU7pLpfDE"
      },
      "source": [
        "# 4. Copy Model Config to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOjuTFbwpfDF"
      },
      "outputs": [],
      "source": [
        "!cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8gpNslpfDF"
      },
      "source": [
        "# 5. Update Config For Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9hRrO_ppfDF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2A0mn4ipfDF"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQA13-afpfDF",
        "outputId": "907496a4-a39d-4b13-8c2c-e5978ecb1f10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 320\n",
              "       width: 320\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " },\n",
              " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false,\n",
              " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ],\n",
              " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vK5lotDpfDF"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP43Ph0JpfDG"
      },
      "outputs": [],
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJvfgwWqpfDG"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3ON7xMpfDG"
      },
      "source": [
        "# 6. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Y2UQmQpfDG"
      },
      "outputs": [],
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMP2XDfQpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=1000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4OXXi-ApfDH",
        "outputId": "117a0e83-012b-466e-b7a6-ccaa349ac5ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKzJc0ywoT3h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3ZsJR-qpfDH",
        "outputId": "cabec5e1-45e6-4f2f-d9cf-297d9c1d0225"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-11-06 21:37:49.468707: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "W1106 21:37:49.477145 4686339584 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "I1106 21:37:49.503545 4686339584 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 1000\n",
            "I1106 21:37:49.521845 4686339584 config_util.py:552] Maybe overwriting train_steps: 1000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1106 21:37:49.522045 4686339584 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages/object_detection/model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W1106 21:37:49.556617 4686339584 deprecation.py:339] From /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages/object_detection/model_lib_v2.py:557: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I1106 21:37:49.566550 4686339584 dataset_builder.py:163] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I1106 21:37:49.567344 4686339584 dataset_builder.py:80] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1106 21:37:49.567492 4686339584 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1106 21:37:49.567556 4686339584 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W1106 21:37:49.576934 4686339584 deprecation.py:339] From /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:101: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1106 21:37:49.632997 4686339584 deprecation.py:339] From /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1106 21:37:55.596524 4686339584 deprecation.py:339] From /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W1106 21:37:57.973611 4686339584 deprecation.py:339] From /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1106 21:37:59.393637 4686339584 deprecation.py:339] From /Users/Aurane/Desktop/TFODCourse/tfod/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2021-11-06 21:38:01.421991: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-11-06 21:38:01.756601: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_YRZu7npfDH"
      },
      "source": [
        "# 7. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80L7-fdPpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYsgEPx9pfDH",
        "outputId": "8632d48b-91d2-45d9-bcb8-c1b172bf6eed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python Tensorflow\\models\\research\\object_detection\\model_main_tf2.py --model_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet --pipeline_config_path=Tensorflow\\workspace\\models\\my_ssd_mobnet\\pipeline.config --checkpoint_dir=Tensorflow\\workspace\\models\\my_ssd_mobnet\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqTV2jGBpfDH",
        "outputId": "e75c0be9-2c47-4668-c14f-3e933be26b3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tfod",
      "language": "python",
      "name": "tfod"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}